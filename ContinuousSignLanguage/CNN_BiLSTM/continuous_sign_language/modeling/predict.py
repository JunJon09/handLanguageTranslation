import CNN_BiLSTM.continuous_sign_language.modeling.functions as functions
import CNN_BiLSTM.models.cnn_bilstm_model as model
import CNN_BiLSTM.continuous_sign_language.modeling.config as model_config
import CNN_BiLSTM.continuous_sign_language.dataset as dataset
import CNN_BiLSTM.continuous_sign_language.init_log as init_log
import torch
import logging

if __name__ == "__main__":
    logger, log_file = init_log.setup_logging()
    logging.info("ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã—ãŸ")
    train_hdf5files, val_hdf5files, test_hdf5files, key2token = dataset.read_dataset()
    train_dataloader, val_dataloader, test_dataloader, in_channels = (
        functions.set_dataloader(
            key2token, train_hdf5files, val_hdf5files, test_hdf5files
        )
    )
    VOCAB = len(key2token)
    out_channels = VOCAB
    save_path = model_config.model_save_path
    device = "cuda" if torch.cuda.is_available() else "cpu"

    cnn_transformer = model.CNNBiLSTMModel(
        in_channels=in_channels,
        kernel_size=model_config.kernel_size,
        cnn_out_channels=model_config.cnn_out_channels,
        stride=model_config.stride,
        padding=model_config.padding,
        dropout_rate=model_config.dropout_rate,
        bias=model_config.bias,
        resNet=model_config.resNet,
        activation=model_config.activation,
        tren_num_layers=model_config.tren_num_layers,
        tren_num_heads=model_config.tren_num_heads,
        tren_dim_ffw=model_config.tren_dim_ffw,
        tren_dropout=model_config.tren_dropout,
        tren_norm_eps=model_config.tren_norm_eps,
        batch_first=model_config.batch_first,
        tren_norm_first=model_config.tren_norm_first,
        tren_add_bias=model_config.tren_add_bias,
        num_classes=out_channels,
        blank_idx=VOCAB - 1,
        temporal_model_type=model_config.temporal_model_type,  # è¿½åŠ 
    )

    load_model, optimizer_loaded, epoch_loaded = functions.load_model(
        cnn_transformer, save_path, device
    )

    # ========================================
    # ğŸ” å¯è¦–åŒ–ãƒ»åˆ†æè¨­å®š
    # ========================================
    VISUALIZE_ATTENTION = True  # True: å¯è¦–åŒ–ã™ã‚‹, False: å¯è¦–åŒ–ã—ãªã„
    GENERATE_CONFUSION_MATRIX = True  # True: æ··åŒè¡Œåˆ—ã‚’ç”Ÿæˆ, False: ç”Ÿæˆã—ãªã„
    VISUALIZE_CONFIDENCE = True  # True: äºˆæ¸¬ä¿¡é ¼åº¦å¯è¦–åŒ–, False: å¯è¦–åŒ–ã—ãªã„
    VISUALIZE_MULTILAYER_FEATURES = True  # True: å¤šå±¤ç‰¹å¾´é‡å¯è¦–åŒ–, False: å¯è¦–åŒ–ã—ãªã„
    MULTILAYER_METHOD = "both"  # "tsne", "umap", "both"

    if (
        VISUALIZE_ATTENTION
        or GENERATE_CONFUSION_MATRIX
        or VISUALIZE_CONFIDENCE
        or VISUALIZE_MULTILAYER_FEATURES
    ):
        analysis_options = []
        if VISUALIZE_ATTENTION:
            analysis_options.append("Attention & CTCå¯è¦–åŒ–")
        if GENERATE_CONFUSION_MATRIX:
            analysis_options.append("æ··åŒè¡Œåˆ—åˆ†æ")
        if VISUALIZE_CONFIDENCE:
            analysis_options.append("äºˆæ¸¬ä¿¡é ¼åº¦å¯è¦–åŒ–")
        if VISUALIZE_MULTILAYER_FEATURES:
            analysis_options.append(f"å¤šå±¤ç‰¹å¾´é‡å¯è¦–åŒ–({MULTILAYER_METHOD})")

        print(f"ğŸ” æ‹¡å¼µåˆ†æãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™")
        print(f"  æœ‰åŠ¹ãªåˆ†æ: {', '.join(analysis_options)}")
        print(
            f"  å¤šå±¤ç‰¹å¾´é‡åˆ†æ: CNNç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã€BiLSTMæ™‚ç³»åˆ—ã€Attentioné‡è¦åº¦ã€æœ€çµ‚çµ±åˆç‰¹å¾´é‡"
        )

        wer, test_times = functions.test_loop(
            dataloader=test_dataloader,
            model=load_model,
            device=device,
            return_pred_times=True,
            blank_id=VOCAB - 1,
            visualize_attention=VISUALIZE_ATTENTION,
            generate_confusion_matrix=GENERATE_CONFUSION_MATRIX,
            visualize_confidence=VISUALIZE_CONFIDENCE,
            visualize_multilayer_features=VISUALIZE_MULTILAYER_FEATURES,
            multilayer_method=MULTILAYER_METHOD,
        )
    else:
        print("ğŸ“Š é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™")
        wer, test_times = functions.test_loop(
            dataloader=test_dataloader,
            model=load_model,
            device=device,
            return_pred_times=True,
            blank_id=VOCAB - 1,
            visualize_attention=False,
            generate_confusion_matrix=False,
            visualize_confidence=False,
            visualize_multilayer_features=False,
            multilayer_method="both",
        )

    print(f"ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆç²¾åº¦: {wer}")
